{
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# General context"
   ],
   "metadata": {},
   "id": "8f6aecfafb899c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The [Learning Agency Lab - Automated Essay Scoring 2.0](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/overview) competition aims to enhance automated essay grading systems to support overburdened teachers, especially in underserved communities. It addresses the limitations of previous efforts by using a larger, more diverse dataset to improve scoring accuracy and fairness. Hosted by Vanderbilt University and The Learning Agency Lab, the competition seeks to develop open-source tools that provide timely feedback to students and integrate more effectively into real-world educational settings. This initiative represents a significant advancement in educational technology, promoting equitable access to reliable automated essay scoring.\n",
    "\n",
    "In this notebook, I conducted exploratory data analysis and developed models using the Deberta V3 architecture ([He et al., 2021](https://arxiv.org/abs/2111.09543)). Additionally, I utilized the Hugging Face `datasets` library in conjunction with PyTorch's `DataLoader` for efficient data handling. I established a training loop using native PyTorch functionalities and modeled the outputs as ordinal values to account for their inherent order.\n",
    "\n",
    "**Todo: add some result**"
   ],
   "metadata": {},
   "id": "ea6aee9af3087c24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inclusion and global variables"
   ],
   "metadata": {},
   "id": "a6b498c5fa91027e"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import List, Any\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import polars as pl\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "# from peft import LoraConfig \n",
    "\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.base import (\n",
    "    BaseEstimator,\n",
    "    ClassifierMixin,\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:28.303518Z",
     "iopub.execute_input": "2024-05-16T14:22:28.304166Z",
     "iopub.status.idle": "2024-05-16T14:22:46.909315Z",
     "shell.execute_reply.started": "2024-05-16T14:22:28.304135Z",
     "shell.execute_reply": "2024-05-16T14:22:46.908345Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:42.344025200Z",
     "start_time": "2024-05-18T16:00:20.229244500Z"
    }
   },
   "execution_count": 1,
   "outputs": [],
   "id": "cf01cfdb11c9978b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set and define global configuration"
   ],
   "metadata": {},
   "id": "334dbc0c169b32b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, I set up a configuration builder that utilizes the Python data class `ConfigurationSetting` to enhance the code's flexibility. This approach allows the code to run with specific configurations in dedicated environments. The instance of `ConfigurationSetting` created by the builder is used throughout the code, replacing hardcoded values."
   ],
   "metadata": {},
   "id": "2dd04eafb242df94"
  },
  {
   "cell_type": "code",
   "source": [
    "DATABRICKS_STR      = \"DATABRICKS\"\n",
    "KAGGLE_STR          = \"KAGGLE\"\n",
    "LOCAL_STR           = \"LOCAL\"\n",
    "MATPLOTBLUE         = \"#1f77b4\"\n",
    "SEED                = 1010\n",
    "DEVICE              = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEBERTA_V3_CKPT     = \"microsoft/deberta-v3-base\"\n",
    "NUM_LABELS          = 5\n",
    "DATALOADER_BATCH    = 10\n",
    "DEBUG               = True\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:46.910879Z",
     "iopub.execute_input": "2024-05-16T14:22:46.911443Z",
     "iopub.status.idle": "2024-05-16T14:22:46.946836Z",
     "shell.execute_reply.started": "2024-05-16T14:22:46.911416Z",
     "shell.execute_reply": "2024-05-16T14:22:46.945860Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:42.367131Z",
     "start_time": "2024-05-18T16:00:42.346334100Z"
    }
   },
   "execution_count": 2,
   "outputs": [],
   "id": "9cbf0b33b060c1f"
  },
  {
   "cell_type": "code",
   "source": [
    "configuration_item = configuration_builder(\n",
    "    model_ckpt=DEBERTA_V3_CKPT,\n",
    "    plot_color=MATPLOTBLUE,\n",
    "    seed=SEED,\n",
    "    device=DEVICE\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:46.985478Z",
     "iopub.execute_input": "2024-05-16T14:22:46.985901Z",
     "iopub.status.idle": "2024-05-16T14:22:46.999376Z",
     "shell.execute_reply.started": "2024-05-16T14:22:46.985868Z",
     "shell.execute_reply": "2024-05-16T14:22:46.998596Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:44.085134900Z",
     "start_time": "2024-05-18T16:00:42.354186500Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'configuration_builder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m configuration_item \u001B[38;5;241m=\u001B[39m \u001B[43mconfiguration_builder\u001B[49m(\n\u001B[0;32m      2\u001B[0m     model_ckpt\u001B[38;5;241m=\u001B[39mDEBERTA_V3_CKPT,\n\u001B[0;32m      3\u001B[0m     plot_color\u001B[38;5;241m=\u001B[39mMATPLOTBLUE,\n\u001B[0;32m      4\u001B[0m     seed\u001B[38;5;241m=\u001B[39mSEED,\n\u001B[0;32m      5\u001B[0m     device\u001B[38;5;241m=\u001B[39mDEVICE\n\u001B[0;32m      6\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'configuration_builder' is not defined"
     ]
    }
   ],
   "id": "e02bf7b490560345"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Warnings are suppressed in my local environment, particularly to remove information about my computing system before the code is pushed to GitHub."
   ],
   "metadata": {},
   "id": "e890f9f8fad6024e"
  },
  {
   "cell_type": "code",
   "source": [
    "if configuration_item.name == LOCAL_STR:\n",
    "    logging.captureWarnings(True)\n",
    "    logger: logging.Logger = logging.getLogger(\"py.warnings\")\n",
    "    logger.addHandler(logging.FileHandler(\"tmp.log\"))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:47.000533Z",
     "iopub.execute_input": "2024-05-16T14:22:47.001178Z",
     "iopub.status.idle": "2024-05-16T14:22:47.008578Z",
     "shell.execute_reply.started": "2024-05-16T14:22:47.001146Z",
     "shell.execute_reply": "2024-05-16T14:22:47.007776Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:44.089148800Z",
     "start_time": "2024-05-18T16:00:44.087138500Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "4ad0f887ab31e924"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {},
   "id": "510888a651886c0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data comes from the Kaggle competition [Learning Agency Lab - Automated Essay Scoring 2.0](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/overview) and can be downloaded from the competition's page."
   ],
   "metadata": {},
   "id": "c8e0490cc9772205"
  },
  {
   "cell_type": "code",
   "source": [
    "if not configuration_item.data_path:\n",
    "    raise ValueError\n",
    "\n",
    "train_ds = pd.read_csv(\n",
    "    filepath_or_buffer=configuration_item.data_path / \"train.csv\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:47.009698Z",
     "iopub.execute_input": "2024-05-16T14:22:47.009968Z",
     "iopub.status.idle": "2024-05-16T14:22:47.779995Z",
     "shell.execute_reply.started": "2024-05-16T14:22:47.009947Z",
     "shell.execute_reply": "2024-05-16T14:22:47.778907Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:44.092144700Z",
     "start_time": "2024-05-18T16:00:44.090146900Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "94de690130ee3965"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the sake of speed, I reduced the dataset size in my local environment. However, even with fewer records, fine-tuning DeBERTA on CPU machines remains challenging and significantly slower without GPU access."
   ],
   "metadata": {},
   "id": "d1c7082c033a8a66"
  },
  {
   "cell_type": "code",
   "source": [
    "# Keep small for local investigation\n",
    "if (configuration_item.name == LOCAL_STR) | DEBUG:\n",
    "    train_ds, _ = train_test_split(\n",
    "        train_ds, \n",
    "        test_size=.99, \n",
    "        random_state=configuration_item.seed, \n",
    "        stratify=train_ds[\"score\"]\n",
    "    )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:47.781245Z",
     "iopub.execute_input": "2024-05-16T14:22:47.781561Z",
     "iopub.status.idle": "2024-05-16T14:22:47.804739Z",
     "shell.execute_reply.started": "2024-05-16T14:22:47.781534Z",
     "shell.execute_reply": "2024-05-16T14:22:47.803855Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:44.095142700Z",
     "start_time": "2024-05-18T16:00:44.093138600Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "d49ec797a52a4aa3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis"
   ],
   "metadata": {},
   "id": "5d6d54ed980ddb4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data wrangling"
   ],
   "metadata": {},
   "id": "11eb1b473f196950"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Turn the score label into ordinal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c89d5ed4e640a4aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ordinal regression is used when the dependent variable (the outcome you're trying to predict) holds an intrinsic order, but the distances between the levels are not known. The classic examples include a Likert scale for surveys (e.g., \"strongly disagree,\" \"disagree,\" \"neutral,\" \"agree,\" \"strongly agree\"), grades (A, B, C, D, F), or in the case at hand, essay scores. The key advantage of ordinal regression is its ability to handle dependent variables that are more nuanced than simple binary outcomes but don’t have the numeric spacing needed for linear regression. For instance, while we know that grade A is higher than grade B, we cannot say that it is exactly two points higher as we might with numerical scores. This is where ordinal regression comes in—it allows the modeling of the rank order of the dependent variable without making assumptions about the value of the intervals between levels. In the context of modeling essay scores, ordinal regression can predict the rank order of the essays' quality. It is particularly apt for this kind of task because it can learn from the order inherent in the scores without assuming equal spacing between score levels. This can result in more accurate models for ordered categorical data, as it respects the nature of the ranking involved. When using ordinal regression, we need to transform the target variable to reflect the ordinal nature. In a standard regression problem, the target is typically a single column of values. In ordinal regression, however, the target is often expanded into a matrix that represents the ranking order. This matrix enables the model to understand and predict not just whether one essay is better than another but the relative ranking across the spectrum of scores. To prepare for ordinal regression, the scores was transformed into an ordinal matrix with a process known as “one-hot encoding” of the ranks. "
   ],
   "metadata": {},
   "id": "1cd6d04b31cdc421"
  },
  {
   "cell_type": "code",
   "source": [
    "def category_to_ordinal(category):\n",
    "    y = np.array(category, dtype=\"int\") \n",
    "    n = y.shape[0]\n",
    "    num_class = np.max(y) \n",
    "    range_values = np.tile(\n",
    "        np.expand_dims(np.arange(num_class), 0), \n",
    "        [n, 1]\n",
    "    ) \n",
    "    ordinal = np.zeros((n, num_class), dtype=\"int\") \n",
    "    ordinal[range_values < np.expand_dims(y, -1)] = 1 \n",
    "    return ordinal"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:48.365705Z",
     "iopub.execute_input": "2024-05-16T14:22:48.365977Z",
     "iopub.status.idle": "2024-05-16T14:22:48.371620Z",
     "shell.execute_reply.started": "2024-05-16T14:22:48.365953Z",
     "shell.execute_reply": "2024-05-16T14:22:48.370648Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:44.116682100Z",
     "start_time": "2024-05-18T16:00:44.098136400Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "4b1103c59582d1e0"
  },
  {
   "cell_type": "code",
   "source": [
    "train_ds[\"labels\"] = category_to_ordinal(train_ds.score.values).tolist()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:48.372627Z",
     "iopub.execute_input": "2024-05-16T14:22:48.372882Z",
     "iopub.status.idle": "2024-05-16T14:22:48.381784Z",
     "shell.execute_reply.started": "2024-05-16T14:22:48.372860Z",
     "shell.execute_reply": "2024-05-16T14:22:48.380922Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2024-05-18T16:00:44.104115800Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "9d18239e2a6e105d"
  },
  {
   "cell_type": "code",
   "source": [
    "display(train_ds.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:48.382844Z",
     "iopub.execute_input": "2024-05-16T14:22:48.383164Z",
     "iopub.status.idle": "2024-05-16T14:22:48.401998Z",
     "shell.execute_reply.started": "2024-05-16T14:22:48.383136Z",
     "shell.execute_reply": "2024-05-16T14:22:48.400913Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2024-05-18T16:00:44.107129300Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "36cc9c353009ecb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create training / validation set"
   ],
   "metadata": {},
   "id": "73cd99b0db4e4495"
  },
  {
   "cell_type": "code",
   "source": [
    "train_set, validation_set = train_test_split(\n",
    "    train_ds, \n",
    "    train_size=.7, \n",
    "    random_state=SEED, \n",
    "    stratify=train_ds.score\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:48.403063Z",
     "iopub.execute_input": "2024-05-16T14:22:48.403814Z",
     "iopub.status.idle": "2024-05-16T14:22:48.411452Z",
     "shell.execute_reply.started": "2024-05-16T14:22:48.403790Z",
     "shell.execute_reply": "2024-05-16T14:22:48.410530Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2024-05-18T16:00:44.111497800Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "565bf8f9d211feaa"
  },
  {
   "cell_type": "code",
   "source": [
    "train_set_tmp = train_set.copy()\n",
    "validation_set_tmp = validation_set.copy()\n",
    "\n",
    "train_set_tmp[\"type\"] = \"Training\"\n",
    "validation_set_tmp[\"type\"] = \"Validation\"\n",
    "# ingnore_index force the creation of a new index.\n",
    "combined_set = pd.concat(\n",
    "    [train_set_tmp, validation_set_tmp], \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "proportion = (\n",
    "    combined_set.groupby(\"type\")[\"score\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ax = sns.barplot(proportion, x=\"score\", y=\"proportion\", hue=\"type\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    percentage = f\"{p.get_height()*100:.0f}%\" # type: ignore\n",
    "    x = p.get_x() + p.get_width() / 2 # type: ignore\n",
    "    y = p.get_height() # type: ignore\n",
    "    ax.text(x, y, percentage, ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.title(\"Comparative Distribution of Scores Proportion in Training and Validation Sets\")\n",
    "plt.xlabel(\"Scores\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.show()\n",
    "\n",
    "del(train_set_tmp)\n",
    "del(validation_set_tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:48.412576Z",
     "iopub.execute_input": "2024-05-16T14:22:48.413179Z",
     "iopub.status.idle": "2024-05-16T14:22:48.796431Z",
     "shell.execute_reply.started": "2024-05-16T14:22:48.413146Z",
     "shell.execute_reply": "2024-05-16T14:22:48.795513Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2024-05-18T16:00:44.114607600Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "8facf148c313605c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The provided plot presents a grouped bar chart depicting the distribution of scores within two distinct datasets: Training and Validation. Each score category from 1 to 6 is represented by a pair of bars—one for the Training set (in blue) and one for the Validation set (in orange). The stratification ensures that the proportion of scores in each score category is consistent across both training and validation sets. This consistency is critical when developing a model for ordinal regression, as it allows the model to learn from a training set that mirrors the real-world or expected distribution of scores. Consequently, when the model is validated, the validation set similarly reflects this distribution, allowing for an accurate assessment of the model's performance. From the visual comparison of the bar heights, it is evident that each score's representation in the training set closely matches its representation in the validation set."
   ],
   "metadata": {},
   "id": "6768819307df2f2b"
  },
  {
   "cell_type": "code",
   "source": [
    "type(validation_set)\n",
    "data_dict = datasets.DatasetDict({\n",
    "    \"training\": datasets.Dataset.from_pandas(df=train_set),\n",
    "    \"validation\": datasets.Dataset.from_pandas(df=validation_set)\n",
    "})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-16T14:22:48.797442Z",
     "iopub.execute_input": "2024-05-16T14:22:48.797733Z",
     "iopub.status.idle": "2024-05-16T14:22:48.841513Z",
     "shell.execute_reply.started": "2024-05-16T14:22:48.797709Z",
     "shell.execute_reply": "2024-05-16T14:22:48.840840Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:00:44.121197800Z",
     "start_time": "2024-05-18T16:00:44.117210900Z"
    }
   },
   "execution_count": null,
   "outputs": [],
   "id": "8bb2f819b37f4b3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling usin Sentence transformer with setfit"
   ],
   "metadata": {},
   "id": "6af63836563ea677"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {},
   "id": "539c1a53601da96c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenize the text"
   ],
   "metadata": {},
   "id": "794b0af2be10c42d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenization is a fundamental process in natural language processing (NLP) where text is segmented into smaller units known as tokens. These tokens may be individual words, characters, or subwords. This segmentation is akin to parsing a sentence into its constituent words or decomposing a word into syllables. "
   ],
   "metadata": {},
   "id": "16cdba6989be742a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Important Note**: The `DataCollatorWithPadding` modifies column names by changing `label` to `labels` (if the column exists). For the sake of conciseness and readability, I have updated all occurrences of `label` to `labels` throughout the code. This specific transformation is detailed in the `__call__` function of the [`DataCollatorWithPadding`](https://github.com/huggingface/transformers/blob/v4.40.2/src/transformers/data/data_collator.py#L236)."
   ],
   "metadata": {},
   "id": "bf4362edda487fb7"
  }
 ]
}
